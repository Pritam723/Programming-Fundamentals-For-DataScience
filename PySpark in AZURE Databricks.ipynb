{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "063f85ca-208b-4062-963f-59b546606774",
   "metadata": {},
   "source": [
    "<h3>PySpark in AZURE Databricks</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea13626-fa3d-4110-b4c6-1eee444a0219",
   "metadata": {},
   "source": [
    "In Databricks we can work with Apache Spark/ PySpark. This platform provide us cluster instances to distribute huge amount of data.\n",
    "Community Version is free. (It works with Azure/AWS/GCP too). Databricks helps\n",
    "to implement MLFlow (CI/CD Pipeline) also.\n",
    "\n",
    "Databricks: Open & Unified data analytics platform for data engineering, data science, ML & analytics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ad6c23-c0ed-4153-94d7-0cd8608d9c82",
   "metadata": {},
   "source": [
    "Go to: https://www.databricks.com/try-databricks\n",
    "\n",
    "For now use community version, not with the cloud platforms. (Upgrade Later if required).\n",
    "\n",
    "After Login go to: https://dbc-4e63c11d-3976.cloud.databricks.com/browse/folders/1164562597117085?o=2109108343072569\n",
    "\n",
    "#### But not able to find Add Cluster Here\n",
    "\n",
    "Check: https://community.cloud.databricks.com later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485dabba-4b39-4ac5-a70c-8e0da763d29b",
   "metadata": {},
   "source": [
    "Select a Cluster Name and Runtime. Spark version depends on it. Onside the cluster we can install other libraries too.\n",
    "\n",
    "We can upload data, or bring from S3, Amazon Kinesis (Livestreaming data), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "250972da-47a1-4b5e-b8a7-d3da54404701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, we will work with a dataset, where we try to predict\n",
    "# a value based on 6 independednt features.\n",
    "# So, we will use Linear Regression. (Check video). Features having\n",
    "# categories. So, give them numerical values using Ordinal Encoding.\n",
    "# There is another way which is called One Hot Encoding.\n",
    "\n",
    "# When we run the code, it shows, \"Running Spark Jobs\".\n",
    "# Why use databricks? Because here we can create clusters having \n",
    "# multiple nodes. If our data is too large, we can chunk the data\n",
    "# and run our Spark Jobs on Multiple Nodes and even on Multiple Clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6a90f8-1acb-4a33-a94e-0840d40fe39f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
